{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puntajes = pd.read_csv(\"../A_INSCRITOS_PUNTAJES_2023_PAES_PUB_MRUN.csv\", sep=\";\")\n",
    "puntajes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "socioeconomic = pd.read_csv(\"../B_SOCIOECONOMICO_DOMICILIO_2023_PAES_PUB_MRUN.csv\", sep=\";\")\n",
    "socioeconomic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_1 = socioeconomic.drop(['FECHA_NACIMIENTO','ANYO_PROCESO', 'CODIGO_REGION_DOMICILIO','CODIGO_PROVINCIA_DOMICILIO','CODIGO_COMUNA_DOMICILIO','NOMBRE_COMUNA_DOMICILIO'], axis=1)\n",
    "#quite ciertos datos de socioeconomic que no ibamos a usar :p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_puntajes = ['MRUN', 'DEPENDENCIA', 'PROMEDIO_NOTAS','PTJE_NEM','PTJE_RANKING','CLEC_REG_ACTUAL','MATE1_REG_ACTUAL','MATE2_REG_ACTUAL','HCSOC_REG_ACTUAL','CIEN_REG_ACTUAL','PROMEDIO_CM_MAX','CLEC_MAX','MATE1_MAX','MATE2_MAX','HCSOC_MAX','CIEN_MAX']\n",
    "new_2 = puntajes[columnas_puntajes]\n",
    "#quite unos datos de puntajes tambien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge entre new_1 y new_2\n",
    "merged_new = pd.merge(new_1,new_2,on='MRUN')\n",
    "merged_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí empieza la limpieza de datos de las columnas de merged_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipos_dato = merged_new.dtypes \n",
    "print(tipos_dato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#cambiar las comas por puntos\n",
    "merged_new['PROMEDIO_CM_MAX'] = merged_new['PROMEDIO_CM_MAX'].str.replace(',', '.').astype(float)\n",
    "merged_new['PROMEDIO_NOTAS'] = merged_new['PROMEDIO_NOTAS'].str.replace(',', '.').astype(float)\n",
    "\n",
    "#para todas las columnas que poseen N o S se cambia por 0 o 1\n",
    "cols = ['DISPOSITIVO_1', 'DISPOSITIVO_2', 'DISPOSITIVO_3', 'DISPOSITIVO_4', 'DISPOSITIVO_5', 'HOGAR_CONEXION_INTERNET', 'ESPACIO_1', 'ESPACIO_2', 'ESPACIO_3', 'ESPACIO_4', 'ESPACIO_5', 'ESPACIO_6', 'ESPACIO_7', 'ESPACIO_8', 'ESPACIO_9']\n",
    "\n",
    "# Valores distintos a 'N' o 'S' se reemplazan por NaN\n",
    "for col in cols:\n",
    "    merged_new[col] = merged_new[col].apply(lambda x: x if x in ['N', 'S'] else np.nan)\n",
    "\n",
    "# Eliminar los NaN\n",
    "merged_new.dropna(subset=cols, inplace=True)\n",
    "\n",
    "# Transformación de tipo\n",
    "for col in cols:\n",
    "    merged_new[col] = merged_new[col].str.replace('N', '0').str.replace('S', '1').astype(int)\n",
    "    print(f\"Columna transformada: {col}\")\n",
    "\n",
    "print(\"\\nDataFrame después de la transformación:\")\n",
    "print(merged_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para los datos Nan que son discretos se cambian a 0, quizas despues puede ser el promedio \n",
    "for col in merged_new.select_dtypes(include=['object']).columns:\n",
    "    merged_new[col] = merged_new[col].replace(' ', '0')\n",
    "    merged_new[col] = merged_new[col].astype(int)\n",
    "    print(f\"Columna transformada: {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clusters con KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccion de columnas para hacer el cluster \n",
    "# data1 = merged_new[['PROMEDIO_CM_MAX','RAZON_PRINCIPAL_PAES','USO_DISPOSITIVO_1','USO_DISPOSITIVO_2','USO_DISPOSITIVO_3','CONEXION_INSUFICIENTE','USO_ESPACIO_1','USO_ESPACIO_2','USO_ESPACIO_3','USO_ESPACIO_4','USO_ESPACIO_5','USO_ESPACIO_6','USO_ESPACIO_7','USO_ESPACIO_8','TRANQUILIDAD_COLEGIO','TRABAJO_GRUPO_COLEGIO']]\n",
    "data1 = merged_new[['PROMEDIO_CM_MAX','RAZON_PRINCIPAL_PAES','USO_DISPOSITIVO_1','USO_DISPOSITIVO_2','USO_DISPOSITIVO_3','CONEXION_INSUFICIENTE','USO_ESPACIO_1','USO_ESPACIO_2','USO_ESPACIO_3','USO_ESPACIO_4','USO_ESPACIO_5','USO_ESPACIO_6','USO_ESPACIO_7','USO_ESPACIO_8','TRANQUILIDAD_COLEGIO','TRABAJO_GRUPO_COLEGIO']]\n",
    "idxs = [1, 4, 7, 13]\n",
    "data = data1[(data1['RAZON_PRINCIPAL_PAES'].isin([1,2,3,4,5,6,8]))& (data1['PROMEDIO_CM_MAX']>=200)]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.feature_selection import GenericUnivariateSelect, f_classif, f_regression\n",
    "\n",
    "#se normalizan los datos\n",
    "normalizer = Normalizer()\n",
    "scaled_data = normalizer.fit_transform(data)\n",
    "\n",
    "#se eligen los atributos que se utilizaran para hacer el cluster usando genericunivariateselect, de ahi lo podemos cambiar por otro, esto era para ver si funcionaba xd\n",
    "y = data['PROMEDIO_CM_MAX']\n",
    "#se supone que al usar f_regression utiliza la correlacion de pearson para determinar que caracteristicas tienen mayor correlacion con promedio_max,\n",
    "#selecciona el 50% de caracteristicas con mayor correlacion\n",
    "#puede usarse percentil o kbest, pero kbest uno determina con un valor fijo\n",
    "selector = GenericUnivariateSelect(score_func=f_regression, mode='percentile', param=50)\n",
    "selector.fit(scaled_data, y)\n",
    "#atributos elegidos\n",
    "selected_features = selector.transform(scaled_data)\n",
    "\n",
    "support = selector.get_support()\n",
    "selected_indices = np.where(support)[0]\n",
    "#nombre de los atributos elegidos\n",
    "selected_feature_names = data.columns[selected_indices]\n",
    "selected_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#revisar cuantos clusters crear\n",
    "#inertia es SSE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline\n",
    "means = []\n",
    "inertias = []\n",
    "def optimize_k_means(data,max_k):\n",
    "    for k in range(1,max_k):\n",
    "        k_means = KMeans(n_clusters=k)\n",
    "        k_means.fit(data)\n",
    "        means.append(k)\n",
    "        inertias.append(k_means.inertia_)\n",
    "\n",
    "    fig = plt.subplots(figsize=(5,5))\n",
    "    plt.plot(means,inertias, 'o-')\n",
    "    plt.xlabel('Number Clusters')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "optimize_k_means(scaled_data,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se hacen dos clusters de kmeans para probar\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "kmeans = KMeans(n_clusters=2) #se toma el numero de clusters dependiendo del grafico de codo y se hace el kmeans clustering\n",
    "kmeans.fit(scaled_data)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "y_pca = scaled_data[:, 0]\n",
    "\n",
    "columnas = np.take(scaled_data, idxs, axis=1)\n",
    "pca2 = PCA(n_components=1, random_state=0)\n",
    "x_pca = pca2.fit_transform(columnas)\n",
    "\n",
    "#se visualiza el grafico\n",
    "plt.scatter(x_pca, y_pca, c=labels, cmap='viridis')\n",
    "plt.title('Clustering K-means con PCA')\n",
    "plt.xlabel('Variables espacios de estudio')\n",
    "plt.ylabel('Puntaje')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
